# Ops Copilot - Project Overview

## Executive Summary

**Ops Copilot** is an AI-powered incident-response assistant designed to help operations teams quickly diagnose and resolve production incidents. The system combines Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and multi-tool orchestration to answer three critical questions during an incident:

1. **What's broken?** - Identify the failing component/service
2. **Why is it broken?** - Root cause analysis using logs, metrics, and deployment history
3. **What should I do next?** - Actionable remediation steps from runbooks

---

## Problem Statement

**Current State:**
- Mean Time To Resolution (MTTR) for production incidents is high (avg 45 minutes)
- On-call engineers spend significant time searching through runbooks, logs, and metrics
- Knowledge is siloed - only senior engineers know where to look
- Repetitive incidents require manual investigation each time

**Desired State:**
- Reduce MTTR by 30% through AI-assisted diagnosis
- Democratize incident response knowledge across all engineers
- Automate evidence gathering from multiple sources
- Learn from historical incidents to improve future responses

---

## Solution Architecture

### High-Level Components

```
User Query â†’ API Gateway â†’ Agent Orchestrator â†’ Tools + RAG â†’ LLM â†’ Structured Response
```

**Core Technologies:**
- **LLM**: GPT-4 Turbo or Claude 3.5 Sonnet for reasoning
- **Agent Framework**: LangGraph for state management and orchestration
- **Vector DB**: Pinecone for semantic runbook search
- **Search Engine**: Elasticsearch for keyword search and log queries
- **Cache**: Redis for performance optimization
- **Database**: PostgreSQL with pgvector for incident history

### Key Features

1. **Hybrid RAG Pipeline**
   - Vector search for semantic similarity
   - Keyword search (BM25) for exact matches
   - Cross-encoder reranking for relevance
   - Deduplication to avoid redundant information

2. **Multi-Tool Orchestration**
   - Log Search: Query application/system logs
   - Metrics Query: Retrieve time-series metrics
   - Deploy History: Get recent deployments
   - Runbook Search: Semantic + keyword search
   - Ticketing: Create/update incident tickets

3. **Structured Output**
   - Hypothesis with confidence score
   - Prioritized next actions
   - Executable commands (with safety flags)
   - Citations for all claims
   - Related historical incidents

4. **Production-Ready Design**
   - Strict iteration budgets (max 5 loops)
   - Circuit breakers for external APIs
   - Comprehensive monitoring and tracing
   - Rate limiting and authentication
   - PII redaction and audit logging

---

## Technical Specifications

### Performance Requirements

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Throughput** | 10,000 req/day | ~7 req/min average, peak 50 req/min |
| **p95 Latency** | < 10 seconds | Incident response is time-critical |
| **p50 Latency** | < 5 seconds | Majority of queries should be fast |
| **Uptime** | 99.9% | Max 43 minutes downtime/month |

### Quality Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Action Correctness** | > 85% | % of correct next actions |
| **Groundedness** | > 95% | % of claims with citations |
| **Hallucination Rate** | < 5% | % of unsupported claims |
| **Root Cause Accuracy** | > 80% | % of correct diagnoses |
| **Tool Efficiency** | < 4 tools | Avg tools called per query |

### Iteration Budget

To prevent infinite loops and ensure predictable performance:

- **Agent reasoning loop**: Max 5 iterations, 30s total timeout
- **Tool retry logic**: Max 3 attempts, 10s per attempt
- **Runbook retrieval**: Single pass (no re-ranking loops)
- **Log search pagination**: Max 3 pages
- **Metrics query**: Single query (no refinement)

---

## Data Flow

### Request Processing Pipeline

1. **Ingestion** (50ms)
   - Validate request schema
   - Authenticate user
   - Check rate limits

2. **Cache Lookup** (20ms)
   - Generate query hash
   - Check L1 (in-memory) and L2 (Redis) cache
   - Return cached response if hit

3. **RAG Pipeline** (3s)
   - Preprocess query (tokenize, extract keywords)
   - Parallel retrieval: vector search + keyword search
   - Reciprocal rank fusion
   - Cross-encoder reranking
   - Deduplication

4. **Tool Execution** (4s)
   - Select relevant tools based on query
   - Execute tools in parallel
   - Aggregate results
   - Build timeline of events

5. **LLM Reasoning** (3s)
   - Construct prompt with context
   - Generate hypothesis and actions
   - Validate structured output
   - Add citations

6. **Storage & Response** (1s)
   - Store incident record in PostgreSQL
   - Cache response in Redis
   - Update metrics
   - Return to user

**Total Latency:** ~9.5s (p95 target: < 10s)

---

## Evaluation Strategy

### Test Datasets

- **50 historical incidents** with known resolutions
- **20 synthetic incidents** for edge cases
- **10 adversarial cases** for robustness testing

### Evaluation Metrics

Implemented using LangSmith:

1. **Action Correctness**: Jaccard similarity between predicted and expected actions
2. **Groundedness**: % of hypothesis claims supported by citations
3. **Time-to-Mitigation Proxy**: Number of steps to resolution
4. **Hallucination Rate**: Inverse of groundedness
5. **Tool Usage Efficiency**: Number of tools called
6. **Root Cause Accuracy**: Binary match with expected root cause

### Continuous Evaluation

- Pre-deployment evaluation gate (must pass all thresholds)
- A/B testing (10% traffic to experimental variants)
- Production monitoring with user feedback collection
- Weekly evaluation reports

---

## Deployment Architecture

### Infrastructure

**Kubernetes Cluster:**
- 3-10 API pods (auto-scaling based on CPU/memory)
- 2-5 worker pods for async processing
- NGINX ingress controller
- Horizontal Pod Autoscaler (HPA)

**Managed Services:**
- PostgreSQL RDS (db.t3.medium)
- Redis ElastiCache (cache.t3.medium)
- Pinecone (1M vectors, Standard plan)
- Elasticsearch (3-node cluster)

### Observability

- **Metrics**: Prometheus + Grafana
- **Tracing**: OpenTelemetry + Jaeger
- **Logging**: Structured JSON logs
- **Alerting**: Prometheus Alertmanager

### Security

- **Authentication**: API keys or JWT tokens
- **Authorization**: Role-based access control (RBAC)
- **Rate Limiting**: 100 requests/hour per user
- **Encryption**: TLS 1.3 in transit, AES-256 at rest
- **Audit Logging**: All actions logged with user context

---

## Cost Estimation

### Monthly Operating Costs

| Component | Cost |
|-----------|------|
| Compute (K8s) | $150 |
| PostgreSQL RDS | $60 |
| Redis ElastiCache | $50 |
| Pinecone | $70 |
| Elasticsearch | $120 |
| LLM API (GPT-4) | $300 |
| Data Transfer | $45 |
| Monitoring | $50 |
| **Total** | **~$845/month** |

**With Optimizations:** ~$575/month
- Caching reduces LLM calls by 40% â†’ Save $120
- Spot instances for workers â†’ Save $50
- Reserved instances (1-year) â†’ Save $100

---

## Implementation Roadmap

### Phase 1: MVP (Weeks 1-4)
- âœ… Core RAG pipeline (vector + keyword search)
- âœ… 2 tools (logs, runbooks)
- âœ… Basic API with authentication
- âœ… Single-team pilot (10 users)

### Phase 2: Beta (Weeks 5-8)
- âœ… All 5 tools integrated
- âœ… Evaluation framework with LangSmith
- âœ… Multi-team rollout (3 teams, 50 users)
- âœ… Performance optimization (caching, async)

### Phase 3: GA (Weeks 9-12)
- âœ… Full observability (metrics, tracing, logging)
- âœ… Auto-scaling and high availability
- âœ… Documentation (API docs, runbook authoring guide)
- âœ… Company-wide rollout (500+ users)

### Future Enhancements (v2+)
- ðŸ”® Slack/Teams bot integration
- ðŸ”® Auto-remediation for known issues
- ðŸ”® Proactive anomaly detection
- ðŸ”® Runbook generation from resolved incidents
- ðŸ”® Multi-cloud support (AWS, GCP, Azure)

---

## Success Metrics

### Business Impact

| Metric | Baseline | Target | Measurement |
|--------|----------|--------|-------------|
| **MTTR** | 45 min | 30 min | 33% reduction |
| **Resolution Rate** | 40% | 60% | % resolved without escalation |
| **On-call Efficiency** | 5 incidents/shift | 8 incidents/shift | 60% increase |
| **User Satisfaction** | N/A | NPS > 50 | Quarterly survey |

### Technical Metrics

- **Latency**: p95 < 10s âœ…
- **Throughput**: 10k req/day âœ…
- **Uptime**: 99.9% âœ…
- **Action Correctness**: > 85% âœ…
- **Groundedness**: > 95% âœ…

---

## Risk Mitigation

| Risk | Impact | Mitigation |
|------|--------|------------|
| **LLM Hallucinations** | High | Strict citation requirements, eval framework |
| **External API Downtime** | Medium | Circuit breakers, fallbacks, caching |
| **Cost Overruns** | Medium | Budget alerts, query limits, aggressive caching |
| **Slow Adoption** | Low | Training, documentation, success stories |
| **Security Breach** | High | Auth, encryption, audit logs, pen testing |

---

## Documentation Index

| Document | Description | Audience |
|----------|-------------|----------|
| [README.md](./README.md) | Quick start and overview | All users |
| [REQUIREMENTS.md](./REQUIREMENTS.md) | Functional & non-functional requirements | Product, Engineering |
| [SYSTEM_DESIGN.md](./SYSTEM_DESIGN.md) | Architecture and components | Engineering |
| [DATAFLOW.md](./DATAFLOW.md) | End-to-end data flow | Engineering |
| [API_SPEC.md](./API_SPEC.md) | REST API specification | Developers |
| [EVALUATION.md](./EVALUATION.md) | Testing and evaluation strategy | ML Engineers, QA |
| [DEPLOYMENT.md](./DEPLOYMENT.md) | Deployment and operations guide | DevOps, SRE |

---

## Team & Ownership

**Core Team:**
- **Product Manager**: Define requirements, prioritize features
- **Tech Lead**: Architecture, code reviews
- **ML Engineer**: RAG pipeline, evaluation
- **Backend Engineer**: API, tools, database
- **DevOps Engineer**: Deployment, monitoring

**Stakeholders:**
- **SRE Team**: Primary users, feedback
- **Security Team**: Security review, compliance
- **Leadership**: Budget approval, success metrics

---

## Conclusion

Ops Copilot represents a significant advancement in incident response automation. By combining state-of-the-art AI with production-grade engineering, we can dramatically reduce MTTR, democratize operational knowledge, and improve the on-call experience for all engineers.

The system is designed with production readiness in mind: strict performance requirements, comprehensive evaluation, robust error handling, and full observability. With the phased rollout plan, we can validate the approach with a small team before scaling to the entire organization.

**Next Steps:**
1. Review and approve this documentation
2. Set up infrastructure (Kubernetes, databases, APIs)
3. Begin Phase 1 implementation
4. Recruit pilot team for early testing

---

**Document Version:** 1.0  
**Last Updated:** 2025-12-20  
**Status:** Ready for Review
